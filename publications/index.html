<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Zheng Xie</title> <meta name="author" content="Zheng Xie"/> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://xie-zheng.cn/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://xie-zheng.cn//">Zheng Xie</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">MLJ</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/pilr-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/pilr-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/pilr-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/pilr.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="he2025mlj" class="col-sm-7"> <div class="title">Probabilistic instance dependent label refinement for noisy label learning</div> <div class="author">Hao-Yuan He, Yu Liu, Ren-Biao Liu,  <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> <em>Machine Learning</em>, 2025. </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10994-024-06668-y" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">he2025mlj</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{He, Hao-Yuan and Liu, Yu and Liu, Ren-Biao and Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistic instance dependent label refinement for noisy label learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{114}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">RecSys</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/recsys24-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/recsys24-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/recsys24-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/recsys24.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="liu2024recsys" class="col-sm-7"> <div class="title">Ranking-Aware Unbiased Post-Click Conversion Rate Estimation via AUC Optimization on Entire Exposure Space</div> <div class="author">Yu Liu, Qinglin Jia, Shuting Shi, Chuhan Wu, Zhaocheng Du,  <em>Zheng Xie</em>, Ruiming Tang, Muyu Zhang, and Ming Li </div> <div class="periodical"> In <em>The 18th ACM Conference on Recommender Systems</em>, 2024. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Estimating the post-click conversion rate (CVR) accurately in ranking systems is crucial for industrial applications. However, this task faces challenges of data sparsity and selection bias, which hinder accurate ranking. Previous approaches attempting to address these challenges often involve a trade-off: either training models on the entire exposure space without unbiased CVR estimation, or providing unbiased CVR estimation without modeling CVR across the entire exposure space. To overcome this trade-off, we propose the Entire-space Weighted Area Under the Curve (EWAUC) framework, which formulates the CVR estimation task as an AUC optimization problem. EWAUC leverages sample reweighting techniques to handle selection bias, and employs pairwise AUC risk to incorporate more information from limited clicked data than cross-entropy and handle data sparsity. In order to model CVR across the entire exposure space in an unbiased manner, EWAUC treats the exposure data as both conversion data and non-conversion data. The properties of AUC risk guarantee the unbiased nature of the entire-space modeling. We provide comprehensive theoretical analysis to validate the unbiased nature of our approach. Additionally, extensive experiments conducted on real-world datasets demonstrate that our approach outperforms state-of-the-art methods in terms of ranking performance for the CVR estimation task.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2024recsys</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Yu and Jia, Qinglin and Shi, Shuting and Wu, Chuhan and Du, Zhaocheng and Xie, Zheng and Tang, Ruiming and Zhang, Muyu and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 18th ACM Conference on Recommender Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ranking-Aware Unbiased Post-Click Conversion Rate Estimation via AUC Optimization on Entire Exposure Space}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">ICML</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/wsabl-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/wsabl-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/wsabl-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/wsabl.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="he2024wsabl" class="col-sm-7"> <div class="title">Ambiguity-Aware Abductive Learning</div> <div class="author">Hao-Yuan He, Hui Sun,  <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>The 41st International Conference on Machine Learning</em>, 2024. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/icml24-hehy.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Abductive Learning (ABL) is a promising framework for integrating sub-symbolic perception and logical reasoning through abduction. In this case, the abduction process provides supervision for the perception model from the background knowledge. Nevertheless, this process naturally contains uncertainty, since the knowledge base may be satisfied by numerous potential candidates. This implies that the result of the abduction process, i.e., a set of candidates, is ambiguous; both correct and incorrect candidates are mixed in this set. The prior art of abductive learning selects the candidate that has the minimal inconsistency of the knowledge base. However, this method overlooks the ambiguity in the abduction process and is prone to error when it fails to identify the correct candidates. To address this, we propose Ambiguity-Aware Abductive Learning (A3BL), which evaluates all potential candidates and their probabilities, thus preventing the model from falling into sub-optimal solutions. Both experimental results and theoretical analyses prove that A3BL markedly enhances ABL by efficiently exploiting the ambiguous abduced supervision.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">he2024wsabl</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{He, Hao-Yuan and Sun, Hui and Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 41st International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ambiguity-Aware Abductive Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">TPAMI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/wsauc-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/wsauc-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/wsauc-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/wsauc.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2023wsauc" class="col-sm-7"> <div class="title">Weakly Supervised AUC Optimization: A Unified Partial AUC Approach</div> <div class="author"> <em>Zheng Xie</em>, Yu Liu, Hao-Yuan He, Ming Li, and Zhi-Hua Zhou </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2024. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.14258" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10413526" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>We propose WSAUC, a unified and robust AUC optimization framework for weakly supervised AUC optimization. The framework covers multiple scenarios including noisy labeled AUC optimization, positive-unlabeled AUC optimization, multi-instance AUC optimization, and semi-supervised AUC optimization with or without noise. The framework achieves robust AUC optimization through a novel variety of AUC, i.e., rpAUC. Theorical and empirical results validate the effectiveness of the framework.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xie2023wsauc</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised AUC Optimization: A Unified Partial AUC Approach}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Liu, Yu and He, Hao-Yuan and Li, Ming and Zhou, Zhi-Hua}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4780--4795}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">AAAI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/umauc-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/umauc-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/umauc-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/umauc.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2024umauc" class="col-sm-7"> <div class="title">AUC Optimization from Multiple Unlabeled Datasets</div> <div class="author"> <em>Zheng Xie</em>, Yu Liu, and Ming Li </div> <div class="periodical"> In <em>The 38th AAAI Conference on Artificial Intelligence</em>, 2024. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/aaai24-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Weakly supervised learning aims to empower machine learning when the perfect supervision is unavailable, which has drawn great attention from researchers. Among various types of weak supervision, one of the most challenging cases is to learn from multiple unlabeled (U) datasets with only a little knowledge of the class priors, or U^m learning for short. In this paper, we study the problem of building an AUC (area under ROC curve) optimization model from multiple unlabeled datasets, which maximizes the pairwise ranking ability of the classifier. We propose U^m-AUC, an AUC optimization approach that converts the U^m data into a multi-label AUC optimization problem, and can be trained efficiently. We show that the proposed U^m-AUC is effective theoretically and empirically.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2024umauc</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Liu, Yu and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 38th AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{AUC} Optimization from Multiple Unlabeled Datasets}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">FCS</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/topaz-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/topaz-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/topaz-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/topaz.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="topaz" class="col-sm-7"> <div class="title">Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking</div> <div class="author">Zhi-Cun Lyu, Xin-Ye Li,  <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> <em>Frontiers of Computer Science</em>, 2024. </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">topaz</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lyu, Zhi-Cun and Li, Xin-Ye and Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers of Computer Science}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Top Pass}: Improve Code Generation by Pass@k-Maximized Code Ranking}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{in press}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">ARXIV</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/brainstorm-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/brainstorm-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/brainstorm-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/brainstorm.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="brainstorm" class="col-sm-7"> <div class="title">Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation</div> <div class="author">Xin-Ye Li, Jiang-Tian Xue,  <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>preprint</em>, 2024. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2305.10679" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Code generation aims to automatically generate source code from high-level task specifications, which can significantly increase productivity of software engineering. Recently, approaches based on large language models (LLMs) have shown remarkable code generation abilities on simple tasks. However, generate code for more complex tasks, such as competition-level problems, remains challenging. In this paper, we introduce Brainstorm framework for code generation. It leverages a brainstorming step that generates and selects diverse thoughts on the problem to facilitate algorithmic reasoning, where the thoughts are possible blueprint of solving the problem. We demonstrate that Brainstorm significantly enhances the ability of LLMs to solve competition-level programming problems, resulting in a more than 50% increase in the pass@k metrics for ChatGPT on the CodeContests benchmark, achieving state-of-the-art performance. Furthermore, our experiments conducted on LeetCode contests show that our framework boosts the ability of ChatGPT to a level comparable to that of human programmers.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">brainstorm</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xin-Ye and Xue, Jiang-Tian and Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{preprint}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">ICDM</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/icdm23-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/icdm23-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/icdm23-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/icdm23.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="du2023beyond" class="col-sm-7"> <div class="title">Beyond Lexical Consistency: Preserving Semantic Consistency for Program Translation</div> <div class="author">Yali Du, Yi-Fan Ma,  <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>The 23rd IEEE International Conference on Data Mining</em>, 2023. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/icdm23-duyl.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Program translation aims to convert the input programs from one programming language to another. Automatic program translation is a prized target of software engineering research, which leverages the reusability of projects and improves the efficiency of development. Recently, thanks to the rapid development of deep learning model architectures and the availability of large-scale parallel corpus of programs, the performance of program translation has been greatly improved. However, the existing program translation models are still far from satisfactory, in terms of the quality of translated programs. In this paper, we argue that a major limitation of the current approaches is lack of consideration of semantic consistency. Beyond lexical consistency, semantic consistency is also critical for the task. To make the program translation model more semantically aware, we propose a general framework named Preserving Semantic Consistency for Program Translation (PSCPT), which considers semantic consistency with regularization in the training objective of program translation and can be easily applied to all encoder-decoder methods with various neural networks (e.g., LSTM, Transformer) as the backbone. We conduct extensive experiments in 7 general programming languages. Experimental results show that with CodeBERT as the backbone, our approach outperforms not only the state-of-the-art open-source models but also the commercial closed large language models (e.g., text-davinci-002, text-davinci-003) on the program translation task. Our replication package (including code, data, etc.) is publicly available at https://github.com/duyali2000/PSCPT .</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">du2023beyond</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Du, Yali and Ma, Yi-Fan and Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 23rd IEEE International Conference on Data Mining}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Beyond Lexical Consistency: Preserving Semantic Consistency for Program Translation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">AAAI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/5-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/5-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/5-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/5.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="sun2023cale" class="col-sm-7"> <div class="title">Cooperative and Adversarial Learning: Co-Enhancing Discriminability and Transferability in Domain Adaptation</div> <div class="author">Hui Sun,  <em>Zheng Xie</em>, Xin-Ye Li, and Ming Li </div> <div class="periodical"> In <em>The 37th AAAI Conference on Artificial Intelligence</em>, 2023. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/aaai23-sunh.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose the CALE framework to unify and enhance the two main objectives of domain adaptation: discriminability and transferability. To achieve this, CALE swaps the cooperative examples of the two objectives, enabling the learning of discriminability and transferability to mutually benefit each other. Additionally, adversarial examples are utilized to enhance the robustness of the two objectives themselves. The framework can be applied to improve current domain adaptation approaches and has been shown to outperform existing state-of-the-art methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sun2023cale</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Hui and Xie, Zheng and Li, Xin-Ye and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 37th AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cooperative and Adversarial Learning: Co-Enhancing Discriminability and Transferability in Domain Adaptation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">AAAI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/4-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/4-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/4-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/4.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2023spst" class="col-sm-7"> <div class="title">Semi-Supervised Learning with Support Isolation by Small-Paced Self-Training</div> <div class="author"> <em>Zheng Xie</em>, Hui Sun, and Ming Li </div> <div class="periodical"> In <em>The 37th AAAI Conference on Artificial Intelligence</em>, 2023. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/aaai23-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this paper, we address a special scenario of semi-supervised learning, where the label missing is caused by a preceding ﬁltering mechanism, i.e., an instance can enter a subsequent process in which its label is revealed if and only if it passes the ﬁltering mechanism. The rejected instances are prohibited to enter the subsequent labeling process due to economical or ethical reasons, making the support of the labeled and unlabeled distributions isolated from each other. In this case, classical semi-supervised learning approaches are prone to fail. We propose a SmallPaced Self-Training framework, which iteratively discovers labeled and unlabeled instance subspaces with bounded Wasserstein distance. We theoretically prove that such a framework may achieve provably low error on the pseudo labels during learning, and validate the approach through experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2023spst</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Sun, Hui and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 37th AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Semi-Supervised Learning with Support Isolation by Small-Paced Self-Training}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">IJCAI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/3-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/3-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/3-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/3.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2018onlinesemiauc" class="col-sm-7"> <div class="title">Cutting the Software Building Efforts in Continuous Integration by Semi-Supervised Online AUC Optimization</div> <div class="author"> <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>The 27th International Joint Conference on Artificial Intelligence</em>, 2018. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ijcai18-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="assets/code/sola.py.zip" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>In this paper, we propose a semi-supervised online AUC optimization algorithm, namely SOLA. This algorithm is suitable for tasks that suffers from streaming data, label scarce, and imbalance. The algorithm is used for solving build outcome prediction in software continuous integration, and achieves superior performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2018onlinesemiauc</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 27th International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cutting the Software Building Efforts in Continuous Integration by Semi-Supervised Online AUC Optimization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">AAAI</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/2-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/2-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/2-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/2.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2018semiauc" class="col-sm-7"> <div class="title">Semi-Supervised AUC Optimization without Guessing Labels of Unlabeled Data</div> <div class="author"> <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>The 32nd AAAI Conference on Artificial Intelligence</em>, 2018. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/aaai18-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="assets/code/sola.py.zip" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>We prove the theoretical property of AUC optimization under semi-supervised learning and positive-unlabeled learning scenarios, and propose a simple yet effective algorithm for semi-supervised and positive-unlabeled AUC optimization. Our algorithm outperforms elaborated approaches on semi-supervised and positive-unlabeled AUC optimization approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2018semiauc</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 32nd AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Semi-Supervised AUC Optimization without Guessing Labels of Unlabeled Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">JOS</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/1-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/1-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/1-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/1.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2017costsensitive" class="col-sm-7"> <div class="title">Cost-Sensitive Margin Distribution Optimization for Software Bug Localization</div> <div class="author"> <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> <em>Journal of Software</em>, 2017. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/jos2811-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Software bug localization problem suffers from data imbalance and heterogeneous code and natural language structure. To tackle this problem, we propose cost-sensitive margin distribution optimization method to enhance the classification tasks under imbalanced scenario, and design a network architecture for processing programming and natural language. Experimental results validates the effectiveness of our method.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xie2017costsensitive</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Software}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cost-Sensitive Margin Distribution Optimization for Software Bug Localization}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">CCML</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/1-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/1-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/1-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/1.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2017ccml" class="col-sm-7"> <div class="title">Cost-Sensitive Margin Distribution Optimization for Software Bug Localization</div> <div class="author"> <em>Zheng Xie</em>, and Ming Li </div> <div class="periodical"> In <em>China Conference on Machine Learning</em>, 2017. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/jos2811-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Software bug localization problem suffers from data imbalance and heterogeneous code and natural language structure. To tackle this problem, we propose cost-sensitive margin distribution optimization method to enhance the classification tasks under imbalanced scenario, and design a network architecture for processing programming and natural language. Experimental results validates the effectiveness of our method.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2017ccml</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie, Zheng and Li, Ming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{China Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cost-Sensitive Margin Distribution Optimization for Software Bug Localization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"> <abbr class="badge">ICMC</abbr> <div class="teaser"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/pub_img/0-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/pub_img/0-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/0-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/0.png" data-zoomable=""> </picture> </figure> </div> </div> <div id="xie2017music" class="col-sm-7"> <div class="title">Music Style Analysis among Haydn, Mozart and Beethoven: an Unsupervised Machine Learning Approach</div> <div class="author">Ru Wen,  <em>Zheng Xie</em>, Kai Chen, Ruoxuan Guo, Kuan Xu, Wenmin Huang, Jiyuan Tian, and Jiang Wu </div> <div class="periodical"> In <em>The 43rd International Computer Music Conference</em>, 2017. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/icmc17-xiez.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We propose an unsupervised music analysis method. We propose a feature extraction method for extracting consecutive note pitch patterns, and use clustering methods for mining the music styles. We apply our method on new built corpus of Haydn, Mozart, and Beethoven. Our discovered pattern fits the Implication-Realization theory, which confirms the validity of our approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie2017music</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wen, Ru and Xie, Zheng and Chen, Kai and Guo, Ruoxuan and Xu, Kuan and Huang, Wenmin and Tian, Jiyuan and Wu, Jiang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 43rd International Computer Music Conference}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Music Style Analysis among Haydn, Mozart and Beethoven: an Unsupervised Machine Learning Approach}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Zheng Xie. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>